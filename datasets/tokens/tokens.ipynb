{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7886ebcf",
   "metadata": {},
   "source": [
    "This code is responsible for calculating, for each provider, the number of tokens from each prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb2f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the ENV file for API KEYS\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c4219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def getPrompts(promptsPath=\"./prompts/\"):\n",
    "    promptsFiles = os.listdir(promptsPath)\n",
    "    prompts = []\n",
    "\n",
    "    for filename in promptsFiles:\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(promptsPath, filename)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "                prompts.append(content)\n",
    "\n",
    "    promptsFiles = [x.replace('.txt','') for x in promptsFiles]\n",
    "    return promptsFiles, prompts\n",
    "\n",
    "files, prompts = getPrompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "models = ['gpt-5','gpt-5-mini']\n",
    "\n",
    "for model in models:\n",
    "    for index, prompt in enumerate(prompts):\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "        print(f\"Model: {model}, Prompt: {files[index]} Size: {len(encoding.encode(prompt))} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a359e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "\n",
    "client = Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "\n",
    "models = ['claude-sonnet-4-5', 'claude-haiku-4-5']\n",
    "\n",
    "for model in models:\n",
    "    for index, prompt in enumerate(prompts):\n",
    "        response = client.messages.count_tokens(\n",
    "        system=prompt,\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Test\"}\n",
    "        ]\n",
    "        )\n",
    "        print(f'{files[index]},{response.input_tokens}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5113c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google - GEMINI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "results = {}\n",
    "\n",
    "models = ['gemini-2.5-pro','gemini-2.5-flash']\n",
    "\n",
    "\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "for model in models:\n",
    "    results[model] = {}\n",
    "    for index, prompt in enumerate(prompts):\n",
    "\n",
    "        response = client.models.count_tokens(\n",
    "        model=model,\n",
    "        contents=prompt\n",
    "        )\n",
    "        \n",
    "        print(files[index])\n",
    "        print(response.total_tokens)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
